@misc{christAutomaticLiverTumor2017,
  title = {Automatic {{Liver}} and {{Tumor Segmentation}} of {{CT}} and {{MRI Volumes}} Using {{Cascaded Fully Convolutional Neural Networks}}},
  author = {Christ, Patrick Ferdinand and Ettlinger, Florian and Gr{\"u}n, Felix and Elshaera, Mohamed Ezzeldin A. and Lipkova, Jana and Schlecht, Sebastian and Ahmaddy, Freba and Tatavarty, Sunil and Bickel, Marc and Bilic, Patrick and Rempfler, Markus and Hofmann, Felix and Anastasi, Melvin D. and Ahmadi, Seyed-Ahmad and Kaissis, Georgios and Holch, Julian and Sommer, Wieland and Braren, Rickmer and Heinemann, Volker and Menze, Bjoern},
  year = {2017},
  month = feb,
  number = {arXiv:1702.05970},
  eprint = {1702.05970},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1702.05970},
  urldate = {2025-05-06},
  abstract = {Automatic segmentation of the liver and hepatic lesions is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of large-scale medical trials and quantitative image analyses. We train and cascade two FCNs for the combined segmentation of the liver and its lesions. As a first step, we train an FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validation results on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94\% for the liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on 38 MRI liver tumor volumes and the public 3DIRCAD dataset.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {files/98/Christ 等 - 2017 - Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neur.pdf}
}

@misc{isenseeNnUNetSelfadaptingFramework2018,
  title = {{{nnU-Net}}: {{Self-adapting Framework}} for {{U-Net-Based Medical Image Segmentation}}},
  shorttitle = {{{nnU-Net}}},
  author = {Isensee, Fabian and Petersen, Jens and Klein, Andre and Zimmerer, David and Jaeger, Paul F. and Kohl, Simon and Wasserthal, Jakob and Koehler, Gregor and Norajitra, Tobias and Wirkert, Sebastian and {Maier-Hein}, Klaus H.},
  year = {2018},
  month = sep,
  number = {arXiv:1809.10486},
  eprint = {1809.10486},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.10486},
  urldate = {2025-05-06},
  abstract = {The U-Net was presented in 2015. With its straight-forward and successful architecture it quickly evolved to a commonly used benchmark in medical image segmentation. The adaptation of the U-Net to novel problems, however, comprises several degrees of freedom regarding the exact architecture, pre-processing, training and inference. These choices are not independent of each other and substantially impact the overall performance. The present paper introduces the nnU-Net (''nonew-Net''), which refers to a robust and self-adapting framework on the basis of 2D and 3D vanilla U-Nets. We argue the strong case for taking away superfluous bells and whistles of many proposed network designs and instead focus on the remaining aspects that make out the performance and generalizability of a method. We evaluate the nnU-Net in the context of the Medical Segmentation Decathlon challenge, which measures segmentation performance in ten disciplines comprising distinct entities, image modalities, image geometries and dataset sizes, with no manual adjustments between datasets allowed. At the time of manuscript submission, nnU-Net achieves the highest mean dice scores across all classes and seven phase 1 tasks (except class 1 in BrainTumour) in the online leaderboard of the challenge.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {files/97/Isensee 等 - 2018 - nnU-Net Self-adapting Framework for U-Net-Based Medical Image Segmentation.pdf}
}

@article{jiangDeepLearningTechniques2022,
  title = {Deep Learning Techniques for Tumor Segmentation: A Review},
  shorttitle = {Deep Learning Techniques for Tumor Segmentation},
  author = {Jiang, Huiyan and Diao, Zhaoshuo and Yao, Yu-Dong},
  year = {2022},
  month = feb,
  journal = {The Journal of Supercomputing},
  volume = {78},
  number = {2},
  pages = {1807--1851},
  issn = {0920-8542, 1573-0484},
  doi = {10.1007/s11227-021-03901-6},
  urldate = {2025-05-07},
  abstract = {Recently, deep learning, especially convolutional neural networks, has achieved the remarkable results in natural image classification and segmentation. At the same time, in the field of medical image segmentation, researchers use deep learning techniques for tasks such as tumor segmentation, cell segmentation, and organ segmentation. Automatic tumor segmentation plays an important role in radiotherapy and clinical practice and is the basis for the implementation of follow-up treatment programs. This paper reviews the tumor segmentation methods based on deep learning in recent years. We first introduce the common medical image types and the evaluation criteria of segmentation results in tumor segmentation. Then, we review the tumor segmentation methods based on deep learning from technique view and tumor view, respectively. The technique view reviews the researches from the architecture of the deep learning and the tumor view reviews from the type of tumors.},
  langid = {english},
  file = {files/118/Jiang 等 - 2022 - Deep learning techniques for tumor segmentation a review.pdf}
}

@misc{liuGeneralisable3DFabric2022,
  title = {Generalisable {{3D Fabric Architecture}} for {{Streamlined Universal Multi-Dataset Medical Image Segmentation}}},
  author = {Liu, Siyu and Dai, Wei and Engstrom, Craig and Fripp, Jurgen and Crozier, Stuart and Dowling, Jason A. and Chandra, Shekhar S.},
  year = {2022},
  month = nov,
  number = {arXiv:2006.15578},
  eprint = {2006.15578},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.15578},
  urldate = {2025-05-06},
  abstract = {Data scarcity is common in deep learning models for medical image segmentation. Previous works proposed multi-dataset learning, either simultaneously or via transfer learning to expand training sets. However, medical image datasets have diverse-sized images and features, and developing a model simultaneously for multiple datasets is challenging. This work proposes Fabric Image Representation Encoding Network (FIRENet), a universal 3D architecture for simultaneous multidataset segmentation and transfer learning involving arbitrary numbers of dataset(s). To handle different-sized image and feature, a 3D fabric module is used to encapsulate many multiscale sub-architectures. An optimal combination of these subarchitectures can be implicitly learnt to best suit the target dataset(s). For diverse-scale feature extraction, a 3D extension of atrous spatial pyramid pooling (ASPP3D) is used in each fabric node for a fine-grained coverage of rich-scale image features. In the first experiment, FIRENet performed 3D universal bone segmentation of multiple musculoskeletal datasets of the human knee, shoulder and hip joints and exhibited excellent simultaneous multi-dataset segmentation performance. When tested for transfer learning, FIRENet further exhibited excellent single dataset performance (when pre-training on a prostate dataset), as well as significantly improved universal bone segmentation performance. The following experiment involves the simultaneous segmentation of the 10 Medical Segmentation Decathlon (MSD) challenge datasets. FIRENet demonstrated good multidataset segmentation results and inter-dataset adaptability of highly diverse image sizes. In both experiments, FIRENet's streamlined multi-dataset learning with one unified network that requires no hyper-parameter tuning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {files/114/Liu 等 - 2022 - Generalisable 3D Fabric Architecture for Streamlined Universal Multi-Dataset Medical Image Segmentat.pdf}
}

@article{muhammadSegmentationLiverTumors2024,
  title = {Segmentation of {{Liver Tumors}} by {{Monai}} and {{PyTorch}} in {{CT Images}} with {{Deep Learning Techniques}}},
  author = {Muhammad, Sabir and Zhang, Jing},
  year = {2024},
  month = jun,
  journal = {Applied Sciences},
  volume = {14},
  number = {12},
  pages = {5144},
  issn = {2076-3417},
  doi = {10.3390/app14125144},
  urldate = {2025-05-07},
  abstract = {Image segmentation and identification are crucial to modern medical image processing techniques. This research provides a novel and effective method for identifying and segmenting liver tumors from public CT images. Our approach leverages the hybrid ResUNet model, a combination of both the ResNet and UNet models developed by the Monai and PyTorch frameworks. The ResNet deep dense network architecture is implemented on public CT scans using the MSD Task03 Liver dataset. The novelty of our method lies in several key aspects. First, we introduce innovative enhancements to the ResUNet architecture, optimizing its performance, especially for liver tumor segmentation tasks. Additionally, by harassing the capabilities of Monai, we streamline the implementation process, eliminating the need for manual script writing and enabling faster, more efficient model development and optimization. The process of preparing images for analysis by a deep neural network involves several steps: data augmentation, a Hounsfield windowing unit, and image normalization. ResUNet network performance is measured by using the DC metric Dice coefficient. This approach, which utilizes residual connections, has proven to be more reliable than other existing techniques. This approach achieved DC values of 0.98\% for detecting liver tumors and 0.87\% for segmentation. Both qualitative and quantitative evaluations show promising results regarding model precision and accuracy. The implications of this research are that it could be used to increase the precision and accuracy of liver tumor detection and liver segmentation, reflecting the potential of the proposed method. This could help in the early diagnosis and treatment of liver cancer, which can ultimately improve patient prognosis.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {files/120/Muhammad和Zhang - 2024 - Segmentation of Liver Tumors by Monai and PyTorch in CT Images with Deep Learning Techniques.pdf}
}

@article{rahmanDeepLearningApproach2022,
  title = {A {{Deep Learning Approach}} for {{Liver}} and {{Tumor Segmentation}} in {{CT Images Using ResUNet}}},
  author = {Rahman, Hameedur and Bukht, Tanvir Fatima Naik and Imran, Azhar and Tariq, Junaid and Tu, Shanshan and Alzahrani, Abdulkareeem},
  year = {2022},
  month = aug,
  journal = {Bioengineering},
  volume = {9},
  number = {8},
  pages = {368},
  issn = {2306-5354},
  doi = {10.3390/bioengineering9080368},
  urldate = {2025-05-07},
  abstract = {According to the most recent estimates from global cancer statistics for 2020, liver cancer is the ninth most common cancer in women. Segmenting the liver is difficult, and segmenting the tumor from the liver adds some difficulty. After a sample of liver tissue is taken, imaging tests, such as magnetic resonance imaging (MRI), computer tomography (CT), and ultrasound (US), are used to segment the liver and liver tumor. Due to overlapping intensity and variability in the position and shape of soft tissues, segmentation of the liver and tumor from computed abdominal tomography images based on shade gray or shapes is undesirable. This study proposed a more efficient method for segmenting liver and tumors from CT image volumes using a hybrid ResUNet model, combining the ResNet and UNet models to address this gap. The two overlapping models were primarily used in this study to segment the liver and for region of interest (ROI) assessment. Segmentation of the liver is done to examine the liver with an abdominal CT image volume. The proposed model is based on CT volume slices of patients with liver tumors and evaluated on the public 3D dataset IRCADB01. Based on the experimental analysis, the true value accuracy for liver segmentation was found to be approximately 99.55\%, 97.85\%, and 98.16\%. The authentication rate of the dice coefficient also increased, indicating that the experiment went well and that the model is ready to use for the detection of liver tumors.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {files/122/Rahman 等 - 2022 - A Deep Learning Approach for Liver and Tumor Segmentation in CT Images Using ResUNet.pdf}
}

@article{songMultiScaleConvolutionalAttention2025,
  title = {Multi-{{Scale Convolutional Attention}} and {{Structural Re-Parameterized Residual-Based 3D U-Net}} for {{Liver}} and {{Liver Tumor Segmentation}} from {{CT}}},
  author = {Song, Ziwei and Wu, Weiwei and Wu, Shuicai},
  year = {2025},
  month = mar,
  journal = {Sensors},
  volume = {25},
  number = {6},
  pages = {1814},
  issn = {1424-8220},
  doi = {10.3390/s25061814},
  urldate = {2025-05-06},
  abstract = {Accurate segmentation of the liver and liver tumors is crucial for clinical diagnosis and treatment. However, the task poses significant challenges due to the complex morphology of tumors, indistinct features of small targets, and the similarity in grayscale values between the liver and surrounding organs. To address these issues, this paper proposes an enhanced 3D UNet architecture, named ELANRes-MSCA-UNet. By incorporating a structural re-parameterized residual module (ELANRes) and a multi-scale convolutional attention module (MSCA), the network significantly improves feature extraction and boundary optimization, particularly excelling in segmenting small targets. Additionally, a two-stage strategy is employed, where the liver region is segmented first, followed by the fine-grained segmentation of tumors, effectively reducing false positive rates. Experiments conducted on the LiTS2017 dataset demonstrate that the ELANRes-MSCA-UNet achieved Dice scores of 97.2\% and 72.9\% for liver and tumor segmentation tasks, respectively, significantly outperforming other state-of-the-art methods. These results validate the accuracy and robustness of the proposed method in medical image segmentation and highlight its potential for clinical applications.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {files/99/Song 等 - 2025 - Multi-Scale Convolutional Attention and Structural Re-Parameterized Residual-Based 3D U-Net for Live.pdf}
}

@article{xieSSCFormerRevisitingConvNetTransformer,
  title = {{{SSCFormer}}: {{Revisiting ConvNet-Transformer Hybrid Framework From Scale-Wise}} and {{Spatial-Channel-Aware Perspectives}} for {{Volumetric Medical Image Segmentation}}},
  author = {Xie, Qinlan and Chen, Yong and Liu, Shenglin and Lu, Xuesong},
  abstract = {Accurate and robust medical image segmentation is crucial for assisting disease diagnosis, making treatment plan, and monitoring disease progression. Adaptive to different scale variations and regions of interest is essential for high accuracy in automatic segmentation methods. Existing methods based on the U-shaped architecture respectively tackling intra- and inter-scale problem with a hierarchical encoder, however, are restricted by the scope of multi-scale modeling. In addition, global attention and scaling attention in regions of interest have not been appropriately adopted, especially for the salient features. To address these two issues, we propose a ConvNet-Transformer hybrid framework named SSCFormer for accurate and versatile medical image segmentation. The intra-scale ResInception and inter-scale transformer bridge are designed to collaboratively capture the intra- and inter-scale features, facilitating the interaction of small-scale disparity information at a single stage with large-scale from multiple stages. Global attention and scaling attention are cleverly integrated from a spatial-channel-aware perspective. The proposed SSCFormer is tested on four different medical image segmentation tasks. Comprehensive experimental results show that SSCFormer outperforms the current state-of-theart methods.},
  langid = {english},
  file = {files/92/Xie 等 - SSCFormer Revisiting ConvNet-Transformer Hybrid Framework From Scale-Wise and Spatial-Channel-Aware.pdf}
}

@article{yangSADSNetRobust3D2024,
  title = {{{SADSNet}}: {{A}} Robust {{3D}} Synchronous Segmentation Network for Liver and Liver Tumors Based on Spatial Attention Mechanism and Deep Supervision},
  shorttitle = {{{SADSNet}}},
  author = {Yang, Sijing and Liang, Yongbo and Wu, Shang and Sun, Peng and Chen, Zhencheng},
  year = {2024},
  month = may,
  journal = {Journal of X-Ray Science and Technology: Clinical Applications of Diagnosis and Therapeutics},
  volume = {32},
  number = {3},
  pages = {707--723},
  issn = {0895-3996, 1095-9114},
  doi = {10.3233/XST-230312},
  urldate = {2025-05-06},
  abstract = {BACKGROUND: Accurately extracting liver and liver tumors from medical images is an important step in lesion localization and diagnosis, surgical planning, and postoperative monitoring. However, the limited number of radiation therapists and a great number of images make this work time-consuming.},
  langid = {english},
  file = {files/100/Yang 等 - 2024 - SADSNet A robust 3D synchronous segmentation network for liver and liver tumors based on spatial at.pdf}
}

@article{yashaswiniDeepLearningTechnique2025,
  title = {Deep Learning Technique for Automatic Liver and Liver Tumor Segmentation in {{CT}} Images},
  author = {Yashaswini, Gowda N and Manjunath, R.V. and Shubha, B and Prabha, Punya and Aishwarya, N and Manu, H M},
  year = {2025},
  month = feb,
  journal = {Journal of Liver Transplantation},
  volume = {17},
  pages = {100251},
  issn = {26669676},
  doi = {10.1016/j.liver.2024.100251},
  urldate = {2025-05-06},
  abstract = {Segmenting the liver and tumors from computed tomography (CT) scans is crucial for medical studies utilizing machine and deep learning techniques. Semantic segmentation, a critical step in this process, is accomplished effectively using fully convolutional neural networks (CNNs). Most Popular networks like UNet and ResUNet leverage diverse resolution features through meticulous planning of convolutional layers and skip connections. This study introduces an automated system employing different convolutional layers that automatically extract features and preserve the spatial information of each feature. In this study, we employed both UNet and a modified Residual UNet on the 3Dircadb (3D Image Reconstruction for computer Assisted Diagnosis database) dataset to segment the liver and tumor. The ResUNet model achieved remarkable results with a Dice Similarity Coefficient of 91.44\% for liver segmentation and 75.84\% for tumor segmentation on 128 {\texttimes} 128 pixel images. These findings validate the effectiveness of the developed models. Notably both models exhibited excellent performance in tumor segmentation. The primary goal of this paper is to utilize deep learning algorithms for liver and tumor segmentation, assessing the model using metrics such as the Dice Similarity Coefficient, accuracy, and precision.},
  langid = {english},
  file = {files/90/Yashaswini 等 - 2025 - Deep learning technique for automatic liver and liver tumor segmentation in CT images.pdf}
}
